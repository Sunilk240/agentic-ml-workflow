from typing import Dict, Any
from langchain_core.tools import tool
from helpers import DATAFRAME_CACHE, PIPELINE_STATE

@tool
def end_session(confirmation: str = "no") -> Dict[str, Any]:
    """
    Ends current ML pipeline session and clears all data.
    User says 'end session', 'reset pipeline', or 'start fresh'.
    """
    if confirmation.lower() not in ["yes", "confirm", "y"]:
        response = "âš ï¸ **End Session Confirmation**\n\n"
        response += "**This will permanently delete:**\n"
        response += "â€¢ All loaded datasets\n"
        response += "â€¢ Trained models and results\n"
        response += "â€¢ Pipeline progress and analysis\n"
        response += "â€¢ Cleaning and feature engineering work\n\n"
        response += "**ðŸ’¡ To confirm, type:**\n"
        response += "â€¢ 'end session yes'\n"
        response += "â€¢ 'reset pipeline confirm'\n"
        response += "â€¢ 'start fresh y'\n\n"
        response += "**Or continue working with current session.**"
        
        return {
            "confirmation_required": True,
            "formatted_response": response,
            "current_datasets": list(DATAFRAME_CACHE.keys()),
            "pipeline_operations": PIPELINE_STATE.get("completed_operations", [])
        }
    
    # Clear all data
    datasets_cleared = list(DATAFRAME_CACHE.keys())
    operations_cleared = PIPELINE_STATE.get("completed_operations", [])
    
    DATAFRAME_CACHE.clear()
    PIPELINE_STATE.clear()
    
    # Reset pipeline state to initial values
    PIPELINE_STATE.update({
        "current_stage": None,
        "completed_operations": [],
        "dataset_info": {},
        "cleaning_analysis": {},
        "feature_analysis": {},
        "models_trained": {},
        "evaluation_results": {}
    })
    
    response = "âœ… **Session Ended Successfully**\n\n"
    response += "**ðŸ—‘ï¸ CLEARED DATA:**\n"
    if datasets_cleared:
        response += f"â€¢ **Datasets:** {', '.join(datasets_cleared)}\n"
    if operations_cleared:
        response += f"â€¢ **Operations:** {', '.join(operations_cleared)}\n"
    response += "â€¢ **Models:** All trained models removed\n"
    response += "â€¢ **Analysis:** All pipeline analysis cleared\n\n"
    
    response += "**ðŸ†• FRESH START:**\n"
    response += "â€¢ Ready to load new dataset\n"
    response += "â€¢ All pipeline stages reset\n"
    response += "â€¢ Memory cleared for optimal performance\n\n"
    
    response += "**ðŸ’¡ NEXT STEPS:**\n"
    response += "â€¢ Load a new dataset to begin ML pipeline\n"
    response += "â€¢ Type 'help' to see available commands\n"
    response += "â€¢ Ask general ML questions anytime\n"
    response += "â€¢ Type 'exit' or 'quit' to leave the application\n"
    
    return {
        "session_ended": True,
        "datasets_cleared": datasets_cleared,
        "operations_cleared": operations_cleared,
        "formatted_response": response,
        "ready_for_new_session": True
    }

@tool
def show_session_status() -> Dict[str, Any]:
    """
    Shows current session status and progress.
    User says 'session status', 'show progress', or 'what have we done'.
    """
    response = "ðŸ“Š **Current Session Status**\n\n"
    
    # Dataset information
    if DATAFRAME_CACHE:
        response += "**ðŸ“ LOADED DATASETS:**\n"
        for dataset_name in DATAFRAME_CACHE.keys():
            df = DATAFRAME_CACHE[dataset_name]
            response += f"â€¢ **{dataset_name}** - {df.shape[0]} rows Ã— {df.shape[1]} columns\n"
    else:
        response += "**ðŸ“ DATASETS:** None loaded\n"
    
    response += "\n"
    
    # Pipeline progress
    completed_ops = PIPELINE_STATE.get("completed_operations", [])
    if completed_ops:
        response += "**âœ… COMPLETED OPERATIONS:**\n"
        for op in completed_ops:
            response += f"â€¢ {op.replace('_', ' ').title()}\n"
    else:
        response += "**âœ… COMPLETED OPERATIONS:** None\n"
    
    response += "\n"
    
    # Current analysis status
    analysis_status = []
    if "cleaning_analysis" in PIPELINE_STATE:
        analysis_status.append("Data Cleaning Analysis")
    if "feature_analysis" in PIPELINE_STATE:
        analysis_status.append("Feature Engineering Analysis")
    if "training_analysis" in PIPELINE_STATE:
        analysis_status.append("Problem Type Detection")
    if "models_trained" in PIPELINE_STATE:
        models_count = len(PIPELINE_STATE["models_trained"].get("algorithms", {}))
        analysis_status.append(f"Model Training ({models_count} models)")
    if "clustering_results" in PIPELINE_STATE:
        analysis_status.append("Clustering Analysis")
    
    if analysis_status:
        response += "**ðŸ” AVAILABLE ANALYSIS:**\n"
        for status in analysis_status:
            response += f"â€¢ {status}\n"
    else:
        response += "**ðŸ” AVAILABLE ANALYSIS:** None\n"
    
    response += "\n**ðŸ’¡ ACTIONS:**\n"
    response += "â€¢ Type 'help' to see available commands\n"
    response += "â€¢ Type 'end session' to start fresh\n"
    response += "â€¢ Continue with current pipeline\n"
    
    return {
        "status_shown": True,
        "datasets_loaded": len(DATAFRAME_CACHE),
        "operations_completed": len(completed_ops),
        "analysis_available": len(analysis_status),
        "formatted_response": response,
        "session_active": len(DATAFRAME_CACHE) > 0 or len(completed_ops) > 0
    }